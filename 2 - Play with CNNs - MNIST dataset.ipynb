{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iv-Tm81YCygR"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAW_v_bfHGmP"
   },
   "source": [
    "To help you understand the fundamentals of deep learning, this demo will walk through the basic steps of building two toy models for classifying handwritten numbers with accuracies surpassing 95%. The model will be a deeper network that introduces the concepts of convolution and pooling.\n",
    "(strongly inspired from this notebook, with some adaptation: https://colab.research.google.com/github/AviatorMoser/keras-mnist-tutorial/blob/master/MNIST%20in%20Keras.ipynb#scrollTo=IDL7UYq7Gz5u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8x4MGgRxKSU"
   },
   "source": [
    "# First play with some kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLCBVqkBxMCf"
   },
   "source": [
    "https://setosa.io/ev/image-kernels/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e40z8rwqHYic"
   },
   "source": [
    "## Prerequisite Python Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1456,
     "status": "ok",
     "timestamp": 1701706377170,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "9Gmx2XwUGM-o"
   },
   "outputs": [],
   "source": [
    "import numpy as np                   # advanced math library\n",
    "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
    "import random                        # for generating random numbers\n",
    "\n",
    "from tensorflow.keras.datasets import mnist     # MNIST dataset is included in Keras\n",
    "from tensorflow.keras.models import Sequential  # Model type to be used\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation # Types of layers to be used in our model\n",
    "from tensorflow.keras.utils import to_categorical              # A useful helper function for one-hot encoding\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bnNuMRYHhvf"
   },
   "source": [
    "## Loading Training Data\n",
    "\n",
    "The MNIST dataset is conveniently bundled within Keras, and we can easily analyze some of its features in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 595,
     "status": "ok",
     "timestamp": 1701706396417,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "geo1NzBiHinJ",
    "outputId": "51026c7d-eb32-4c6a-cb2c-f8e24e123abe"
   },
   "outputs": [],
   "source": [
    "# The MNIST data is split between 60,000 28 x 28 pixel training images and 10,000 28 x 28 pixel images\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qqPSSc0Hsy1"
   },
   "source": [
    "Using matplotlib, we can plot some sample images from the training set directly into this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "executionInfo": {
     "elapsed": 3196,
     "status": "ok",
     "timestamp": 1701706463827,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "W8HaCYL8HvcU",
    "outputId": "131b8015-2e33-47f0-fba6-3ebf5db8c328"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (9,9) # Make the figures a bit bigger\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    num = random.randint(0, len(X_train))\n",
    "    plt.imshow(X_train[num], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Class {}\".format(y_train[num]))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-2CaaX4H4cl"
   },
   "source": [
    "Let's examine a single digit a little closer, and print out the array representing the last digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1701706468806,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "mX8O18nHH-_t",
    "outputId": "b96084d1-2b9b-4cbd-816e-7c4c76af114e"
   },
   "outputs": [],
   "source": [
    "# just a little function for pretty printing a matrix\n",
    "def matprint(mat, fmt=\"g\"):\n",
    "    col_maxes = [max([len((\"{:\"+fmt+\"}\").format(x)) for x in col]) for col in mat.T]\n",
    "    for x in mat:\n",
    "        for i, y in enumerate(x):\n",
    "            print((\"{:\"+str(col_maxes[i])+fmt+\"}\").format(y), end=\"  \")\n",
    "        print(\"\")\n",
    "\n",
    "# now print!\n",
    "matprint(X_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlY4iccyIbsN"
   },
   "source": [
    "Each pixel is an 8-bit integer from 0-255. 0 is full black, while 255 is full white. This what we call a single-channel pixel. It's called monochrome.\n",
    "\n",
    "Fun-fact! Your computer screen has three channels for each pixel: red, green, blue. Each of these channels also likely takes an 8-bit integer. 3 channels -- 24 bits total -- 16,777,216 possible colors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B30gnaBcIgcz"
   },
   "source": [
    "## Formatting the input data layer\n",
    "\n",
    "We'll  normalize the inputs to be in the range [0-1] rather than [0-255]. Normalizing inputs is generally recommended, so that any additional dimensions (for other network architectures) are of the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 209,
     "status": "ok",
     "timestamp": 1701706677761,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "Vd7lMR8aI4Yw",
    "outputId": "b4dcd414-de07-4dd3-f56f-fa1a9612916b"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 28, 28, 1) # add an additional dimension to represent the single-channel\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255                              # normalize each value for each pixel for the entire vector for each input\n",
    "X_test /= 255\n",
    "\n",
    "print(\"Training matrix shape\", X_train.shape)\n",
    "print(\"Testing matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8raIJWJsJE30"
   },
   "source": [
    "We then modify our classes (unique digits) to be in the one-hot format, i.e.\n",
    "\n",
    "\n",
    "```\n",
    "0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "etc.\n",
    "```\n",
    "\n",
    "If the final output of our network is very close to one of these classes, then it is most likely that class. For example, if the final output is:\n",
    "\n",
    "```\n",
    "[0, 0.94, 0, 0, 0, 0, 0.06, 0, 0]\n",
    "```\n",
    "then it is most probable that the image is that of the digit `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1701706689375,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "7h_DxTKxJFyY"
   },
   "outputs": [],
   "source": [
    "nb_classes = 10 # number of unique digits, 0 to 9\n",
    "\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhxlI9uVJOnB"
   },
   "source": [
    "## Building a \"Deep\" Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzOFprpsQrYQ"
   },
   "source": [
    "\n",
    "\n",
    "> ðŸ’¡ Don't forget to activate GPUs on your notebook!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1701706748832,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "NyKz6stKO60r"
   },
   "outputs": [],
   "source": [
    "# import some additional tools\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 855,
     "status": "ok",
     "timestamp": 1701707186951,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "ZcasGJJkPuRO"
   },
   "outputs": [],
   "source": [
    "model = Sequential()                                 # Linear stacking of layers\n",
    "\n",
    "# ðŸ’¡ Choose your activation!\n",
    "activation = 'relu'\n",
    "\n",
    "# Convolution Layer 1\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1))) # 32 different 3x3 kernels -- so 32 feature maps\n",
    "convLayer01 = Activation(activation)                 # activation\n",
    "model.add(convLayer01)\n",
    "\n",
    "# Convolution Layer 2\n",
    "model.add(Conv2D(32, (3, 3)))                        # 32 different 3x3 kernels -- so 32 feature maps\n",
    "model.add(Activation(activation))                    # activation\n",
    "convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
    "model.add(convLayer02)\n",
    "\n",
    "# Convolution Layer 3\n",
    "model.add(Conv2D(64,(3, 3)))                         # 64 different 3x3 kernels -- so 64 feature maps\n",
    "convLayer03 = Activation(activation)                 # activation\n",
    "model.add(convLayer03)\n",
    "\n",
    "# Convolution Layer 4\n",
    "model.add(Conv2D(64, (3, 3)))                        # 64 different 3x3 kernels -- so 64 feature maps\n",
    "model.add(Activation(activation))                    # activation\n",
    "convLayer04 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
    "model.add(convLayer04)\n",
    "\n",
    "model.add(Flatten())  # The next layer is a Dense layer... what needs to be done here?\n",
    "\n",
    "# Fully Connected Layer 5\n",
    "model.add(Dense(512))                                # 512 FCN nodes\n",
    "model.add(Activation(activation))                    # activation\n",
    "\n",
    "# Fully Connected Layer 6\n",
    "model.add(Dense(10))                                 # final 10 FCN nodes\n",
    "model.add(Activation('softmax'))                     # softmax activation in order to get probabilities per class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TlVdP6zsWlB"
   },
   "source": [
    "ðŸ’¡TODO: before running the next cell, can you guess the shape and number of parameters of each layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1701707189070,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "c67QHb48P97p",
    "outputId": "53bdb2a3-b4cd-44cf-b06f-c0b1077e33a9"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1701707440658,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "4uScTdpGqyNB",
    "outputId": "9af63cb6-fd17-4cad-e8c0-dfe269bf3258"
   },
   "outputs": [],
   "source": [
    "# Let's vizualize the model with all the dimensions!\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True, dpi=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1701707451531,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "uM46fxqqQAmm"
   },
   "outputs": [],
   "source": [
    "# ðŸ’¡ Choose some stuff yourself!\n",
    "optimizer = 'adam'\n",
    "loss = 'categorical_crossentropy'  # helper: https://keras.io/api/losses/probabilistic_losses/\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1701707453849,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "FQkgboz3QFA_"
   },
   "outputs": [],
   "source": [
    "# data augmentation prevents overfitting by slightly changing the data randomly\n",
    "# Keras has a great built-in feature to do automatic augmentation\n",
    "# In order to begin with a simple model, no additionnal data is added. It will come later...\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "\n",
    "# Of course, no data augmentation for the test set.\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1701707487579,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "ueecZBiYQKq3"
   },
   "outputs": [],
   "source": [
    "# We can then feed our data in batches\n",
    "# This method actually results in significant memory savings\n",
    "# because we are actually LOADING the data into the network in batches before processing each batch\n",
    "\n",
    "# Before the data was all loaded into memory, but then processed in batches.\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_generator = gen.flow(X_train, Y_train, batch_size=BATCH_SIZE)\n",
    "test_generator = test_gen.flow(X_test, Y_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52551,
     "status": "ok",
     "timestamp": 1701707562436,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "4lo94PTBQRca",
    "outputId": "b3ece4b7-70c1-46bd-8f00-94a21041699a"
   },
   "outputs": [],
   "source": [
    "# We can now train our model which is fed data by our batch loader\n",
    "# Steps per epoch should always be total size of the set divided by the batch size\n",
    "\n",
    "# SIGNIFICANT MEMORY SAVINGS (important for larger, deeper networks)\n",
    "\n",
    "NB_EPOCHS = 5\n",
    "\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=len(X_train)//BATCH_SIZE,\n",
    "          epochs=NB_EPOCHS,\n",
    "          verbose=1,\n",
    "          validation_data=test_generator,\n",
    "          validation_steps=len(X_test)//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1809,
     "status": "ok",
     "timestamp": 1701707712127,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "__Tr5d01RXSP",
    "outputId": "d790b456-6e06-4901-dcde-4131464b2c48"
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1227,
     "status": "ok",
     "timestamp": 1701707717675,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "zpci77-rjjne",
    "outputId": "961f50b7-bba4-4e04-f6d3-7f1a21d33e50"
   },
   "outputs": [],
   "source": [
    "# Let's do predictions on all the test set\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ud0NVysCl2Tq"
   },
   "source": [
    "Let's vizualize performances!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1701710782163,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "GkxGk3rUjoM0",
    "outputId": "bb7d28ad-746d-42aa-a64a-a464b71836ab"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Since the last layer is a softmax, it provides us probabilities for each class.\n",
    "# We need to take the argmax in order to get the real prediction of the model.\n",
    "y_pred = np.argmax(prediction, axis=1)\n",
    "\n",
    "def plot_cm(labels, predictions):\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title(\"Confusion matrix (non-normalized))\")\n",
    "    plt.ylabel(\"Actual label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "\n",
    "plot_cm(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpSaWeMVFAPt"
   },
   "source": [
    "# Let's vizualize the layers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1701710806539,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "-RC7JqUGmM2T"
   },
   "outputs": [],
   "source": [
    "# ðŸ’¡choose any image to want by specifying the index, here the 3nd image of the test set.\n",
    "img_index = 3\n",
    "img = X_test[img_index]\n",
    "img = np.expand_dims(img, axis=0) # Keras requires the image to be in 4D, so we add an extra dimension to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1701710877829,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "cDvMofB1RtIm"
   },
   "outputs": [],
   "source": [
    "# Not important to understand how this function work -- It just plots a convolution layer\n",
    "\n",
    "def visualize(layer):\n",
    "    inputs = model.inputs\n",
    "\n",
    "    _convout1_f = K.function(inputs, [layer.output])\n",
    "\n",
    "    def convout1_f(X):\n",
    "        # The [0] is to disable the training phase flag\n",
    "        return _convout1_f([X])\n",
    "\n",
    "    convolutions = convout1_f(img)\n",
    "    convolutions = np.squeeze(convolutions)\n",
    "\n",
    "    print ('Shape of conv:', convolutions.shape)\n",
    "\n",
    "    m = convolutions.shape[2]\n",
    "    n = int(np.ceil(np.sqrt(m)))\n",
    "\n",
    "    # Visualization of each filter of the layer\n",
    "    fig = plt.figure(figsize=(15,12))\n",
    "    for i in range(m):\n",
    "        ax = fig.add_subplot(n,n,i+1)\n",
    "        ax.imshow(convolutions[:,:,i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 753
    },
    "executionInfo": {
     "elapsed": 914,
     "status": "ok",
     "timestamp": 1701710892302,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "ZgyE8DxeR0n5",
    "outputId": "c737fe5c-f397-4b10-c292-d4593fa2ef4e"
   },
   "outputs": [],
   "source": [
    "# Print the current image\n",
    "plt.imshow(X_test[img_index].reshape(28,28), cmap='gray', interpolation='none');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4994,
     "status": "ok",
     "timestamp": 1701710911283,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "BsJtHtaZR3h2",
    "outputId": "22d102bf-a53e-403a-db99-48854f4ac79f"
   },
   "outputs": [],
   "source": [
    "# ðŸ’¡ BEFORE RUNNING: can you guess the shape of the first feature map?\n",
    "visualize(convLayer01) # visualize first set of feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4859,
     "status": "ok",
     "timestamp": 1701710934676,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "jNoqYp1rZY2y",
    "outputId": "c8cb59ca-8543-4b3b-9258-5597cc9034cc"
   },
   "outputs": [],
   "source": [
    "# ðŸ’¡ BEFORE RUNNING: can you guess the shape of the first feature map?\n",
    "visualize(convLayer02) # visualize second set of feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6948,
     "status": "ok",
     "timestamp": 1701710943998,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "gree1-5pZaX0",
    "outputId": "6bfee61a-ecaa-4b52-fd61-8d4119c1c9af"
   },
   "outputs": [],
   "source": [
    "# ðŸ’¡ BEFORE RUNNING: can you guess the shape of the first feature map?\n",
    "visualize(convLayer03)# visualize third set of feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7726,
     "status": "ok",
     "timestamp": 1701710959571,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "8-4qEI9nZb2H",
    "outputId": "46404827-317c-491e-c201-2b8c1875dfe4"
   },
   "outputs": [],
   "source": [
    "# ðŸ’¡ BEFORE RUNNING: can you guess the shape of the first feature map?\n",
    "visualize(convLayer04)# visualize fourth set of feature maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yJJWNFpnVSw"
   },
   "source": [
    "If you want to go deeper on the vizualization, you have this great notebook: https://colab.research.google.com/github/nguyenhoa93/cnn-visualization-keras-tf2/blob/master/visualization.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLHt2Yh-bTqX"
   },
   "source": [
    "ðŸ’¡**YOUR TURN**\n",
    "\n",
    "Now, please try to play with the different activation functions!\n",
    "\n",
    "- Which one train faster?\n",
    "- Which one give best results?\n",
    "\n",
    "Please, play also with the number of layers: can you remove some of them and see the impact?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_I307v5qkXm1"
   },
   "source": [
    "# Now, let's try data augmentation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aa3ND39p9G3"
   },
   "source": [
    "In each epoch, the ImageDataGenerator applies a transformation on the images you have and use the transformed images for training. The set of transformations includes rotation, zooming, etc. By doing this you're somehow creating new data (i.e. also called data augmentation), but obviously the generated images are not totally different from the original ones. This way the learned model may be more robust and accurate as it is trained on different variations of the same image.\n",
    "It means we use a different transformation of each image in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1701711004333,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "rD5icRxtkZ1L"
   },
   "outputs": [],
   "source": [
    "# We'll change the image data generator so that it generates images in real time.\n",
    "# See all the possibles parameters here, and then vizualize the impacts:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "\n",
    "# ðŸ’¡ Play with it and vizualize it!\n",
    "gen = ImageDataGenerator(rotation_range=8,\n",
    "                         width_shift_range=0.08,\n",
    "                         shear_range=0.3,\n",
    "                         height_shift_range=0.08,\n",
    "                         zoom_range=0.08,\n",
    "                         vertical_flip=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 753
    },
    "executionInfo": {
     "elapsed": 658,
     "status": "ok",
     "timestamp": 1701711026677,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "p2AINgVPlA9S",
    "outputId": "3de58789-5561-41f1-82b0-754b8bbf2e70"
   },
   "outputs": [],
   "source": [
    "# Take one image to vuzualize the transformations applied\n",
    "img = X_train[0]\n",
    "plt.imshow(img[:,:, -1], cmap='gray', interpolation='none');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "executionInfo": {
     "elapsed": 5354,
     "status": "ok",
     "timestamp": 1701711050602,
     "user": {
      "displayName": "Thomas",
      "userId": "17969775338756094822"
     },
     "user_tz": -60
    },
    "id": "tn2AGLwnlDA2",
    "outputId": "11eaf831-c2c3-4d33-9c7f-041b8b7ab471"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "# Look at 9 augmentations for that image\n",
    "for img_batch in gen.flow(img.reshape(1, 28, 28, 1), batch_size=9):\n",
    "    for img_ in img_batch:\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(img_[:,:,-1], cmap='gray')\n",
    "        i = i + 1\n",
    "    if i >= 9:\n",
    "        break\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTEjQOQcqVrj"
   },
   "source": [
    "ðŸ’¡ Now, relaunch the training with this data augmentation, and try to see the impacts!\n",
    "\n",
    "ðŸ’¡ What if the data augmentation is not a good quality (for example, too much zoom)?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1ZEMSqVdgUhtB-K9uZYkmSu2nC5AmUPmL",
     "timestamp": 1701703912229
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
